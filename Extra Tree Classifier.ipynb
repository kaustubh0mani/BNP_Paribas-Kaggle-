{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "<class 'pandas.core.index.Index'>\n",
      "v3\n",
      "['A' 'B' 'C' 'nan']\n",
      "['A' 'B' 'C' 'nan']\n",
      "v24\n",
      "['A' 'B' 'C' 'D' 'E']\n",
      "['A' 'B' 'C' 'D' 'E']\n",
      "v30\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'nan']\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'nan']\n",
      "v31\n",
      "['A' 'B' 'C' 'nan']\n",
      "['A' 'B' 'C' 'nan']\n",
      "v47\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J']\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J']\n",
      "v52\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'nan']\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'nan']\n",
      "v56\n",
      "['A' 'AA' 'AB' 'AC' 'AE' 'AF' 'AG' 'AH' 'AI' 'AJ' 'AK' 'AL' 'AM' 'AN' 'AO'\n",
      " 'AP' 'AR' 'AS' 'AT' 'AU' 'AV' 'AW' 'AX' 'AY' 'AZ' 'B' 'BA' 'BC' 'BD' 'BE'\n",
      " 'BF' 'BG' 'BH' 'BI' 'BJ' 'BK' 'BL' 'BM' 'BN' 'BO' 'BP' 'BQ' 'BR' 'BS' 'BT'\n",
      " 'BU' 'BV' 'BW' 'BX' 'BY' 'BZ' 'C' 'CA' 'CB' 'CC' 'CD' 'CE' 'CF' 'CG' 'CH'\n",
      " 'CI' 'CJ' 'CK' 'CL' 'CM' 'CN' 'CO' 'CP' 'CQ' 'CS' 'CT' 'CV' 'CW' 'CX' 'CY'\n",
      " 'CZ' 'D' 'DA' 'DB' 'DC' 'DD' 'DE' 'DF' 'DG' 'DH' 'DI' 'DJ' 'DK' 'DL' 'DM'\n",
      " 'DN' 'DO' 'DP' 'DQ' 'DR' 'DS' 'DT' 'DU' 'DV' 'DW' 'DX' 'DY' 'DZ' 'E' 'F'\n",
      " 'G' 'H' 'I' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' 'nan']\n",
      "['A' 'AA' 'AB' 'AC' 'AE' 'AF' 'AG' 'AH' 'AI' 'AJ' 'AK' 'AL' 'AM' 'AN' 'AO'\n",
      " 'AP' 'AR' 'AS' 'AT' 'AU' 'AV' 'AW' 'AX' 'AY' 'AZ' 'B' 'BA' 'BC' 'BD' 'BE'\n",
      " 'BF' 'BG' 'BH' 'BI' 'BJ' 'BK' 'BL' 'BM' 'BN' 'BO' 'BP' 'BQ' 'BR' 'BS' 'BT'\n",
      " 'BU' 'BV' 'BW' 'BX' 'BY' 'BZ' 'C' 'CA' 'CB' 'CC' 'CD' 'CE' 'CF' 'CG' 'CH'\n",
      " 'CI' 'CJ' 'CK' 'CL' 'CM' 'CN' 'CO' 'CP' 'CQ' 'CS' 'CT' 'CV' 'CW' 'CX' 'CY'\n",
      " 'CZ' 'D' 'DA' 'DB' 'DC' 'DD' 'DE' 'DF' 'DG' 'DH' 'DI' 'DJ' 'DK' 'DL' 'DM'\n",
      " 'DN' 'DO' 'DP' 'DQ' 'DR' 'DS' 'DT' 'DU' 'DV' 'DW' 'DX' 'DY' 'DZ' 'E' 'F'\n",
      " 'G' 'H' 'I' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' 'nan']\n",
      "v66\n",
      "['A' 'B' 'C']\n",
      "['A' 'B' 'C']\n",
      "v71\n",
      "['A' 'B' 'C' 'D' 'F' 'G' 'I' 'K' 'L']\n",
      "['A' 'B' 'C' 'D' 'F' 'G' 'I' 'K' 'L']\n",
      "v74\n",
      "['A' 'B' 'C']\n",
      "['A' 'B' 'C']\n",
      "v75\n",
      "['A' 'B' 'C' 'D']\n",
      "['A' 'B' 'C' 'D']\n",
      "v79\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R']\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R']\n",
      "v91\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'nan']\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'nan']\n",
      "v107\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'nan']\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'nan']\n",
      "v110\n",
      "['A' 'B' 'C']\n",
      "['A' 'B' 'C']\n",
      "v112\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
      " 'S' 'T' 'U' 'V' 'nan']\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
      " 'S' 'T' 'U' 'V' 'nan']\n",
      "v113\n",
      "['A' 'AA' 'AB' 'AC' 'AD' 'AE' 'AF' 'AG' 'AH' 'AI' 'AJ' 'AK' 'B' 'C' 'D' 'E'\n",
      " 'F' 'G' 'H' 'I' 'J' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X'\n",
      " 'Y' 'Z' 'nan']\n",
      "['A' 'AA' 'AB' 'AC' 'AD' 'AE' 'AF' 'AG' 'AH' 'AI' 'AJ' 'AK' 'B' 'C' 'D' 'E'\n",
      " 'F' 'G' 'H' 'I' 'J' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X'\n",
      " 'Y' 'Z' 'nan']\n",
      "v125\n",
      "['A' 'AA' 'AB' 'AC' 'AD' 'AE' 'AF' 'AG' 'AH' 'AI' 'AJ' 'AK' 'AL' 'AM' 'AN'\n",
      " 'AO' 'AP' 'AQ' 'AR' 'AS' 'AT' 'AU' 'AV' 'AW' 'AX' 'AY' 'AZ' 'B' 'BA' 'BB'\n",
      " 'BC' 'BD' 'BE' 'BF' 'BG' 'BH' 'BI' 'BJ' 'BK' 'BL' 'BM' 'BN' 'BO' 'BP' 'BQ'\n",
      " 'BR' 'BS' 'BT' 'BU' 'BV' 'BW' 'BX' 'BY' 'BZ' 'C' 'CA' 'CB' 'CC' 'CD' 'CE'\n",
      " 'CF' 'CG' 'CH' 'CI' 'CJ' 'CK' 'CL' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M'\n",
      " 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' 'nan']\n",
      "['A' 'AA' 'AB' 'AC' 'AD' 'AE' 'AF' 'AG' 'AH' 'AI' 'AJ' 'AK' 'AL' 'AM' 'AN'\n",
      " 'AO' 'AP' 'AQ' 'AR' 'AS' 'AT' 'AU' 'AV' 'AW' 'AX' 'AY' 'AZ' 'B' 'BA' 'BB'\n",
      " 'BC' 'BD' 'BE' 'BF' 'BG' 'BH' 'BI' 'BJ' 'BK' 'BL' 'BM' 'BN' 'BO' 'BP' 'BQ'\n",
      " 'BR' 'BS' 'BT' 'BU' 'BV' 'BW' 'BX' 'BY' 'BZ' 'C' 'CA' 'CB' 'CC' 'CD' 'CE'\n",
      " 'CF' 'CG' 'CH' 'CI' 'CJ' 'CK' 'CL' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M'\n",
      " 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' 'nan']\n",
      "Clearing...\n",
      "Training...\n",
      "Predict...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "def Binarize(columnName, df, features=None):\n",
    "    df[columnName] = df[columnName].astype(str)\n",
    "    if(features is None):\n",
    "        features = np.unique(df[columnName].values)\n",
    "    print(features)\n",
    "    for x in features:\n",
    "        df[columnName+'_' + x] = df[columnName].map(lambda y:\n",
    "                                                    1 if y == x else 0)\n",
    "    df.drop(columnName, inplace=True, axis=1)\n",
    "    return df, features\n",
    "\n",
    "\n",
    "def MungeData(train, test):\n",
    "\n",
    "    features = train.columns[2:]\n",
    "    print(type(features))\n",
    "    for col in features:\n",
    "        if((train[col].dtype == 'object') and (col!=\"v22\")):\n",
    "            print(col)\n",
    "            train, binfeatures = Binarize(col, train)\n",
    "            test, _ = Binarize(col, test, binfeatures)\n",
    "            nb = BernoulliNB()\n",
    "            nb.fit(train[col+'_'+binfeatures].values, train.target.values)\n",
    "            train[col] = \\\n",
    "                nb.predict_proba(train[col+'_'+binfeatures].values)[:, 1]\n",
    "            test[col] = \\\n",
    "                nb.predict_proba(test[col+'_'+binfeatures].values)[:, 1]\n",
    "            train.drop(col+'_'+binfeatures, inplace=True, axis=1)\n",
    "            test.drop(col+'_'+binfeatures, inplace=True, axis=1)\n",
    "            train[col] = train[col].astype(float)\n",
    "            test[col] = test[col].astype(float)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "print('Load data...')\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "train, test = MungeData(train, test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "target = train['target'].values\n",
    "train = train.drop(['ID','target','v8','v23','v25','v31','v36','v37','v46','v51','v53','v54','v63','v73','v75','v79','v81','v82','v89','v92','v95','v105','v107','v108','v109','v110','v116','v117','v118','v119','v123','v124','v128'],axis=1)\n",
    "\n",
    "id_test = test['ID'].values\n",
    "test = test.drop(['ID','v8','v23','v25','v31','v36','v37','v46','v51','v53','v54','v63','v73','v75','v79','v81','v82','v89','v92','v95','v105','v107','v108','v109','v110','v116','v117','v118','v119','v123','v124','v128'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Clearing...')\n",
    "for (train_name, train_series), (test_name, test_series) in zip(train.iteritems(),test.iteritems()):\n",
    "    if train_series.dtype == 'O':\n",
    "        #for objects: factorize\n",
    "        train[train_name], tmp_indexer = pd.factorize(train[train_name])\n",
    "        test[test_name] = tmp_indexer.get_indexer(test[test_name])\n",
    "        #but now we have -1 values (NaN)\n",
    "    else:\n",
    "        #for int or float: fill NaN\n",
    "        tmp_len = len(train[train_series.isnull()])\n",
    "        if tmp_len>0:\n",
    "            #print \"mean\", train_series.mean()\n",
    "            train.loc[train_series.isnull(), train_name] = -999 \n",
    "        #and Test\n",
    "        tmp_len = len(test[test_series.isnull()])\n",
    "        if tmp_len>0:\n",
    "            test.loc[test_series.isnull(), test_name] = -999\n",
    "\n",
    "X_train = train\n",
    "X_test = test\n",
    "print('Training...')\n",
    "extc = ExtraTreesClassifier(n_estimators=750,max_features= 60,criterion= 'entropy',min_samples_split= 4,\n",
    "                            max_depth= 40, min_samples_leaf= 2, n_jobs = -1)      \n",
    "\n",
    "extc.fit(X_train,target) \n",
    "\n",
    "print('Predict...')\n",
    "y_pred = extc.predict_proba(X_test)\n",
    "#print y_pred\n",
    "\n",
    "pd.DataFrame({\"ID\": id_test, \"PredictedProb\": y_pred[:,1]}).to_csv('extra_trees.csv',index=False)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = pd.read_csv(\"extra_trees.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PredictedProb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.431172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.921556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.558333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.777412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.616536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0.958111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>0.585889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0.950444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>0.825546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17</td>\n",
       "      <td>0.781295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>0.761556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19</td>\n",
       "      <td>0.771556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>0.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>0.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26</td>\n",
       "      <td>0.793282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29</td>\n",
       "      <td>0.923333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38</td>\n",
       "      <td>0.966000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41</td>\n",
       "      <td>0.896944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44</td>\n",
       "      <td>0.522333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>45</td>\n",
       "      <td>0.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>47</td>\n",
       "      <td>0.678382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>48</td>\n",
       "      <td>0.580105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>49</td>\n",
       "      <td>0.926558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>0.787689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>53</td>\n",
       "      <td>0.574889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>56</td>\n",
       "      <td>0.489049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>59</td>\n",
       "      <td>0.799250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>60</td>\n",
       "      <td>0.653137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>64</td>\n",
       "      <td>0.787551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114363</th>\n",
       "      <td>228650</td>\n",
       "      <td>0.715438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114364</th>\n",
       "      <td>228656</td>\n",
       "      <td>0.431111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114365</th>\n",
       "      <td>228661</td>\n",
       "      <td>0.636098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114366</th>\n",
       "      <td>228662</td>\n",
       "      <td>0.918889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114367</th>\n",
       "      <td>228664</td>\n",
       "      <td>0.754333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114368</th>\n",
       "      <td>228665</td>\n",
       "      <td>0.639667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114369</th>\n",
       "      <td>228667</td>\n",
       "      <td>0.901806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114370</th>\n",
       "      <td>228669</td>\n",
       "      <td>0.887111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114371</th>\n",
       "      <td>228672</td>\n",
       "      <td>0.803444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114372</th>\n",
       "      <td>228674</td>\n",
       "      <td>0.504376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114373</th>\n",
       "      <td>228675</td>\n",
       "      <td>0.604428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114374</th>\n",
       "      <td>228676</td>\n",
       "      <td>0.759000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114375</th>\n",
       "      <td>228678</td>\n",
       "      <td>0.795164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114376</th>\n",
       "      <td>228679</td>\n",
       "      <td>0.745028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114377</th>\n",
       "      <td>228681</td>\n",
       "      <td>0.914667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114378</th>\n",
       "      <td>228685</td>\n",
       "      <td>0.768182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114379</th>\n",
       "      <td>228686</td>\n",
       "      <td>0.937333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114380</th>\n",
       "      <td>228687</td>\n",
       "      <td>0.771828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114381</th>\n",
       "      <td>228689</td>\n",
       "      <td>0.725755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114382</th>\n",
       "      <td>228690</td>\n",
       "      <td>0.802222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114383</th>\n",
       "      <td>228692</td>\n",
       "      <td>0.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114384</th>\n",
       "      <td>228693</td>\n",
       "      <td>0.792889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114385</th>\n",
       "      <td>228694</td>\n",
       "      <td>0.737989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114386</th>\n",
       "      <td>228696</td>\n",
       "      <td>0.795700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114387</th>\n",
       "      <td>228698</td>\n",
       "      <td>0.785927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114388</th>\n",
       "      <td>228700</td>\n",
       "      <td>0.928222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114389</th>\n",
       "      <td>228703</td>\n",
       "      <td>0.219444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114390</th>\n",
       "      <td>228704</td>\n",
       "      <td>0.922622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114391</th>\n",
       "      <td>228706</td>\n",
       "      <td>0.936804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114392</th>\n",
       "      <td>228709</td>\n",
       "      <td>0.571281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114393 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  PredictedProb\n",
       "0            0       0.431172\n",
       "1            1       0.863000\n",
       "2            2       0.921556\n",
       "3            7       0.558333\n",
       "4           10       0.777412\n",
       "5           11       0.616536\n",
       "6           13       0.958111\n",
       "7           14       0.585889\n",
       "8           15       0.950444\n",
       "9           16       0.825546\n",
       "10          17       0.781295\n",
       "11          18       0.761556\n",
       "12          19       0.771556\n",
       "13          20       0.874000\n",
       "14          25       0.948000\n",
       "15          26       0.793282\n",
       "16          29       0.923333\n",
       "17          38       0.966000\n",
       "18          41       0.896944\n",
       "19          44       0.522333\n",
       "20          45       0.238000\n",
       "21          47       0.678382\n",
       "22          48       0.580105\n",
       "23          49       0.926558\n",
       "24          50       0.787689\n",
       "25          53       0.574889\n",
       "26          56       0.489049\n",
       "27          59       0.799250\n",
       "28          60       0.653137\n",
       "29          64       0.787551\n",
       "...        ...            ...\n",
       "114363  228650       0.715438\n",
       "114364  228656       0.431111\n",
       "114365  228661       0.636098\n",
       "114366  228662       0.918889\n",
       "114367  228664       0.754333\n",
       "114368  228665       0.639667\n",
       "114369  228667       0.901806\n",
       "114370  228669       0.887111\n",
       "114371  228672       0.803444\n",
       "114372  228674       0.504376\n",
       "114373  228675       0.604428\n",
       "114374  228676       0.759000\n",
       "114375  228678       0.795164\n",
       "114376  228679       0.745028\n",
       "114377  228681       0.914667\n",
       "114378  228685       0.768182\n",
       "114379  228686       0.937333\n",
       "114380  228687       0.771828\n",
       "114381  228689       0.725755\n",
       "114382  228690       0.802222\n",
       "114383  228692       0.788000\n",
       "114384  228693       0.792889\n",
       "114385  228694       0.737989\n",
       "114386  228696       0.795700\n",
       "114387  228698       0.785927\n",
       "114388  228700       0.928222\n",
       "114389  228703       0.219444\n",
       "114390  228704       0.922622\n",
       "114391  228706       0.936804\n",
       "114392  228709       0.571281\n",
       "\n",
       "[114393 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
